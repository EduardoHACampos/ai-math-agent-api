# API de Chat com Agente de IA e Ferramentas MatemÃ¡ticas ğŸ¤–ğŸ§®

Este projeto Ã© uma API desenvolvida com **FastAPI** que integra um Agente de InteligÃªncia Artificial capaz de conduzir conversas naturais e executar cÃ¡lculos matemÃ¡ticos com alta precisÃ£o.
O sistema utiliza o **Ollama** para rodar modelos LLM localmente (recomendado: Llama 3.1) e implementa o padrÃ£o de *Function Calling* para delegar operaÃ§Ãµes matemÃ¡ticas a uma ferramenta Python segura.

---

## ğŸš€ Funcionalidades

* **Chat Inteligente:** ConversaÃ§Ã£o natural com compreensÃ£o de contexto.
* **Ferramenta MatemÃ¡tica (Math Tool):** Detecta automaticamente quando o usuÃ¡rio faz perguntas que exigem cÃ¡lculos (somas, multiplicaÃ§Ãµes, trigonometria, etc.) e executa essas operaÃ§Ãµes com precisÃ£o via Python.
* **Sistema de ProteÃ§Ã£o:** VerificaÃ§Ãµes de seguranÃ§a para evitar alucinaÃ§Ãµes da IA (ex.: tentar calcular palavras) e execuÃ§Ã£o do cÃ³digo matemÃ¡tico em ambiente restrito.
* **Tratamento de Erros:** Respostas claras e padronizadas para falhas de conexÃ£o com a LLM ou erros internos.

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3.10+**
* **FastAPI**
* **Ollama**
* **Pydantic**

---

## ğŸ“‹ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

1. **Python 3.10+**
2. **Ollama** rodando na sua mÃ¡quina

---

## âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clonar o repositÃ³rio

```bash
git clone <URL_DO_SEU_REPOSITORIO>
cd ai-math-agent-api
```

### 2. Criar o Ambiente Virtual

**Windows (PowerShell):**

```bash
python -m venv .venv
.venv\Scripts\activate
```

**Linux/Mac (Bash):**

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

> O `requirements.txt` deve incluir: `fastapi`, `uvicorn`, `ollama`, `python-dotenv`

### 4. Configurar o Modelo no Ollama

RecomendaÃ§Ã£o: **Llama 3.1** (suporte nativo a Tools).

```bash
ollama pull llama3.1
```

### 5. Criar o arquivo `.env`

Crie um arquivo `.env` na raiz do projeto:

```ini
# Modelo a ser usado
MODEL_NAME=llama3.1

# URL do servidor Ollama
OLLAMA_BASE_URL=http://localhost:11434
```

---

## â–¶ï¸ Como Executar

### 1. Iniciar o Ollama

```bash
ollama run llama3.1
```

### 2. Iniciar o servidor da API

```bash
python -m uvicorn app.main:app --reload
```

A API ficarÃ¡ disponÃ­vel em: **[http://127.0.0.1:8000](http://127.0.0.1:8000)**

---

## ğŸ§ª Como Testar

Use a documentaÃ§Ã£o interativa (Swagger UI):

ğŸ‘‰ **[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)**

Abra o endpoint **POST /chat**, clique em *Try it out* e envie um JSON.

---

## ğŸ“¤ Exemplos de RequisiÃ§Ã£o

### CÃ¡lculo MatemÃ¡tico (Usa a Math Tool)

```json
{
  "message": "Quanto Ã© 1234 * 5678?"
}
```

### Conversa Geral

```json
{
  "message": "OlÃ¡, como vocÃª pode me ajudar?"
}
```

### CÃ¡lculo Complexo

```json
{
  "message": "Qual Ã© a raiz quadrada de 144?"
}
```

---

## ğŸ“‚ Estrutura do Projeto

```
app/
â”‚â”€â”€ main.py                # Entrada da aplicaÃ§Ã£o FastAPI
â”‚â”€â”€ config.py              # ConfiguraÃ§Ãµes e variÃ¡veis de ambiente
â”‚
â”œâ”€â”€ routes/                # Endpoints da API
â”œâ”€â”€ services/
â”‚     â”œâ”€â”€ agent_service.py # LÃ³gica do agente + integraÃ§Ã£o com Ollama
â”‚     â””â”€â”€ math_tools.py    # Mecanismo matemÃ¡tico seguro
â”‚
â””â”€â”€ models/                # Modelos Pydantic (Request/Response)
```
